{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ef85b48",
   "metadata": {},
   "source": [
    "Assignment 2: Personalized Course Recommendation Engine\n",
    "1. Background & Context Online learning platforms host thousands of courses across domains—learners often feel overwhelmed by choices. A personalized recommender that understands both course content and individual learner profiles can boost engagement and completion rates by suggesting the most relevant next steps.\n",
    "2. Problem Statement “Design and implement a Course Recommendation Engine that—given a user query (completed courses + a short interests blurb)—returns the top-5 most relevant courses from a catalog of course offerings, using embedding models and a vector database for semantic matching.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77fdf1e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35f6139d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install pypdf sentence-transformers faiss-cpu --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e603610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1759948019.360222    4878 fork_posix.cc:71] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-chroma\n",
      "  Downloading langchain_chroma-0.2.6-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting langchain-core>=0.3.76 (from langchain-chroma)\n",
      "  Downloading langchain_core-0.3.78-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from langchain-chroma) (2.3.2)\n",
      "Collecting chromadb>=1.0.20 (from langchain-chroma)\n",
      "  Downloading chromadb-1.1.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
      "Collecting build>=1.0.3 (from chromadb>=1.0.20->langchain-chroma)\n",
      "  Using cached build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from chromadb>=1.0.20->langchain-chroma) (2.11.7)\n",
      "Collecting pybase64>=1.4.1 (from chromadb>=1.0.20->langchain-chroma)\n",
      "  Using cached pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain-chroma) (0.35.0)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb>=1.0.20->langchain-chroma)\n",
      "  Using cached posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from chromadb>=1.0.20->langchain-chroma) (4.15.0)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading onnxruntime-1.23.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from chromadb>=1.0.20->langchain-chroma) (1.36.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from chromadb>=1.0.20->langchain-chroma) (1.36.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from chromadb>=1.0.20->langchain-chroma) (0.22.0)\n",
      "Collecting pypika>=0.48.9 (from chromadb>=1.0.20->langchain-chroma)\n",
      "  Using cached pypika-0.48.9-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from chromadb>=1.0.20->langchain-chroma) (4.67.1)\n",
      "Collecting overrides>=7.3.1 (from chromadb>=1.0.20->langchain-chroma)\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb>=1.0.20->langchain-chroma)\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from chromadb>=1.0.20->langchain-chroma) (1.74.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading typer-0.19.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from chromadb>=1.0.20->langchain-chroma) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from chromadb>=1.0.20->langchain-chroma) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb>=1.0.20->langchain-chroma)\n",
      "  Using cached mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from chromadb>=1.0.20->langchain-chroma) (3.11.3)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from chromadb>=1.0.20->langchain-chroma) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from chromadb>=1.0.20->langchain-chroma) (14.1.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from chromadb>=1.0.20->langchain-chroma) (4.25.1)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from langchain-core>=0.3.76->langchain-chroma) (0.4.27)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from langchain-core>=0.3.76->langchain-chroma) (1.33)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from langchain-core>=0.3.76->langchain-chroma) (25.0)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb>=1.0.20->langchain-chroma)\n",
      "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: anyio in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb>=1.0.20->langchain-chroma) (4.10.0)\n",
      "Requirement already satisfied: certifi in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb>=1.0.20->langchain-chroma) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb>=1.0.20->langchain-chroma) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb>=1.0.20->langchain-chroma) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=1.0.20->langchain-chroma) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.3.76->langchain-chroma) (3.0.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb>=1.0.20->langchain-chroma) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb>=1.0.20->langchain-chroma) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb>=1.0.20->langchain-chroma) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb>=1.0.20->langchain-chroma) (0.27.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma) (2.40.3)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading websocket_client-1.9.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: requests in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma) (2.32.5)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting urllib3<2.4.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma)\n",
      "  Using cached durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.76->langchain-chroma) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.76->langchain-chroma) (0.24.0)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=1.0.20->langchain-chroma)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: protobuf in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb>=1.0.20->langchain-chroma) (6.32.0)\n",
      "Requirement already satisfied: sympy in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb>=1.0.20->langchain-chroma) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb>=1.0.20->langchain-chroma) (8.7.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.20->langchain-chroma) (1.70.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading opentelemetry_sdk-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading opentelemetry_api-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.58b0 (from opentelemetry-sdk>=1.2.0->chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.20->langchain-chroma) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.20->langchain-chroma) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from pydantic>=1.9->chromadb>=1.0.20->langchain-chroma) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from pydantic>=1.9->chromadb>=1.0.20->langchain-chroma) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from pydantic>=1.9->chromadb>=1.0.20->langchain-chroma) (0.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from rich>=10.11.0->chromadb>=1.0.20->langchain-chroma) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from rich>=10.11.0->chromadb>=1.0.20->langchain-chroma) (2.19.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from tokenizers>=0.13.2->chromadb>=1.0.20->langchain-chroma) (0.34.4)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from typer>=0.9.0->chromadb>=1.0.20->langchain-chroma) (8.2.1)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb>=1.0.20->langchain-chroma)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain-chroma)\n",
      "  Using cached httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain-chroma) (1.1.1)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain-chroma)\n",
      "  Using cached uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain-chroma)\n",
      "  Using cached watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain-chroma) (15.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma) (4.9.1)\n",
      "Requirement already satisfied: filelock in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.20->langchain-chroma) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.20->langchain-chroma) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.20->langchain-chroma) (1.1.9)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=1.0.20->langchain-chroma) (3.23.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=1.0.20->langchain-chroma) (0.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from requests->kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma) (3.4.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from anyio->httpx>=0.27.0->chromadb>=1.0.20->langchain-chroma) (1.3.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb>=1.0.20->langchain-chroma)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib->kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma)\n",
      "  Using cached oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb>=1.0.20->langchain-chroma) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma) (0.6.1)\n",
      "Downloading langchain_chroma-0.2.6-py3-none-any.whl (12 kB)\n",
      "Downloading chromadb-1.1.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.9/19.9 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.78-py3-none-any.whl (449 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.6/449.6 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached build-1.3.0-py3-none-any.whl (23 kB)\n",
      "Downloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
      "Downloading onnxruntime-1.23.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl (19 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_sdk-1.37.0-py3-none-any.whl (131 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.9/131.9 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.37.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Using cached posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "Using cached pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
      "Downloading typer-0.19.2-py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Using cached durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Using cached httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
      "Using cached watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
      "Downloading websocket_client-1.9.0-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.6/82.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Using cached pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Installing collected packages: pypika, flatbuffers, durationpy, websocket-client, uvloop, urllib3, shellingham, pyproject_hooks, pybase64, overrides, opentelemetry-proto, oauthlib, mmh3, importlib-resources, humanfriendly, httptools, bcrypt, watchfiles, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, build, typer, requests-oauthlib, posthog, opentelemetry-semantic-conventions, onnxruntime, opentelemetry-sdk, kubernetes, opentelemetry-exporter-otlp-proto-grpc, langchain-core, chromadb, langchain-chroma\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.5.0\n",
      "    Uninstalling urllib3-2.5.0:\n",
      "      Successfully uninstalled urllib3-2.5.0\n",
      "  Attempting uninstall: opentelemetry-api\n",
      "    Found existing installation: opentelemetry-api 1.36.0\n",
      "    Uninstalling opentelemetry-api-1.36.0:\n",
      "      Successfully uninstalled opentelemetry-api-1.36.0\n",
      "  Attempting uninstall: opentelemetry-semantic-conventions\n",
      "    Found existing installation: opentelemetry-semantic-conventions 0.57b0\n",
      "    Uninstalling opentelemetry-semantic-conventions-0.57b0:\n",
      "      Successfully uninstalled opentelemetry-semantic-conventions-0.57b0\n",
      "  Attempting uninstall: opentelemetry-sdk\n",
      "    Found existing installation: opentelemetry-sdk 1.36.0\n",
      "    Uninstalling opentelemetry-sdk-1.36.0:\n",
      "      Successfully uninstalled opentelemetry-sdk-1.36.0\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.75\n",
      "    Uninstalling langchain-core-0.3.75:\n",
      "      Successfully uninstalled langchain-core-0.3.75\n",
      "Successfully installed bcrypt-5.0.0 build-1.3.0 chromadb-1.1.1 coloredlogs-15.0.1 durationpy-0.10 flatbuffers-25.9.23 httptools-0.6.4 humanfriendly-10.0 importlib-resources-6.5.2 kubernetes-34.1.0 langchain-chroma-0.2.6 langchain-core-0.3.78 mmh3-5.2.0 oauthlib-3.3.1 onnxruntime-1.23.1 opentelemetry-api-1.37.0 opentelemetry-exporter-otlp-proto-common-1.37.0 opentelemetry-exporter-otlp-proto-grpc-1.37.0 opentelemetry-proto-1.37.0 opentelemetry-sdk-1.37.0 opentelemetry-semantic-conventions-0.58b0 overrides-7.7.0 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 pyproject_hooks-1.2.0 requests-oauthlib-2.0.0 shellingham-1.5.4 typer-0.19.2 urllib3-2.3.0 uvloop-0.21.0 watchfiles-1.1.0 websocket-client-1.9.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "465e6219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2206a7e4",
   "metadata": {},
   "source": [
    "Assigning the embedding model and model name for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "092fabd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "embedding_model_name = \"models/gemini-embedding-001\"\n",
    "model_name = \"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcc055fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C001</td>\n",
       "      <td>Foundations of Machine Learning</td>\n",
       "      <td>Understand foundational machine learning algor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C002</td>\n",
       "      <td>Deep Learning with TensorFlow and Keras</td>\n",
       "      <td>Explore neural network architectures using Ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C003</td>\n",
       "      <td>Natural Language Processing Fundamentals</td>\n",
       "      <td>Dive into NLP techniques for processing and un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C004</td>\n",
       "      <td>Computer Vision and Image Processing</td>\n",
       "      <td>Learn the principles of computer vision and im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C005</td>\n",
       "      <td>Reinforcement Learning Basics</td>\n",
       "      <td>Get introduced to reinforcement learning parad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  course_id                                     title  \\\n",
       "0      C001           Foundations of Machine Learning   \n",
       "1      C002   Deep Learning with TensorFlow and Keras   \n",
       "2      C003  Natural Language Processing Fundamentals   \n",
       "3      C004      Computer Vision and Image Processing   \n",
       "4      C005             Reinforcement Learning Basics   \n",
       "\n",
       "                                         description  \n",
       "0  Understand foundational machine learning algor...  \n",
       "1  Explore neural network architectures using Ten...  \n",
       "2  Dive into NLP techniques for processing and un...  \n",
       "3  Learn the principles of computer vision and im...  \n",
       "4  Get introduced to reinforcement learning parad...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"assignment2dataset.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "401098a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title_descrp\"]=df[\"title\"]+\"//\"+df[\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1548b706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>title_descrp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C001</td>\n",
       "      <td>Foundations of Machine Learning</td>\n",
       "      <td>Understand foundational machine learning algor...</td>\n",
       "      <td>Foundations of Machine Learning//Understand fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C002</td>\n",
       "      <td>Deep Learning with TensorFlow and Keras</td>\n",
       "      <td>Explore neural network architectures using Ten...</td>\n",
       "      <td>Deep Learning with TensorFlow and Keras//Explo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C003</td>\n",
       "      <td>Natural Language Processing Fundamentals</td>\n",
       "      <td>Dive into NLP techniques for processing and un...</td>\n",
       "      <td>Natural Language Processing Fundamentals//Dive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C004</td>\n",
       "      <td>Computer Vision and Image Processing</td>\n",
       "      <td>Learn the principles of computer vision and im...</td>\n",
       "      <td>Computer Vision and Image Processing//Learn th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C005</td>\n",
       "      <td>Reinforcement Learning Basics</td>\n",
       "      <td>Get introduced to reinforcement learning parad...</td>\n",
       "      <td>Reinforcement Learning Basics//Get introduced ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  course_id                                     title  \\\n",
       "0      C001           Foundations of Machine Learning   \n",
       "1      C002   Deep Learning with TensorFlow and Keras   \n",
       "2      C003  Natural Language Processing Fundamentals   \n",
       "3      C004      Computer Vision and Image Processing   \n",
       "4      C005             Reinforcement Learning Basics   \n",
       "\n",
       "                                         description  \\\n",
       "0  Understand foundational machine learning algor...   \n",
       "1  Explore neural network architectures using Ten...   \n",
       "2  Dive into NLP techniques for processing and un...   \n",
       "3  Learn the principles of computer vision and im...   \n",
       "4  Get introduced to reinforcement learning parad...   \n",
       "\n",
       "                                        title_descrp  \n",
       "0  Foundations of Machine Learning//Understand fo...  \n",
       "1  Deep Learning with TensorFlow and Keras//Explo...  \n",
       "2  Natural Language Processing Fundamentals//Dive...  \n",
       "3  Computer Vision and Image Processing//Learn th...  \n",
       "4  Reinforcement Learning Basics//Get introduced ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8ce5c6",
   "metadata": {},
   "source": [
    "Generating vector embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d83eb3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=embedding_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "725a70c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "vector_db_path = \"VectorDB_Chroma_assignment_2\"\n",
    "os.makedirs(vector_db_path,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ee9e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip uninstall opentelemetry-sdk opentelemetry-exporter-otlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1d56759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_texts(texts=df[\"title_descrp\"].to_list(),\n",
    "                                 embedding= embeddings, \n",
    "                                 persist_directory=vector_db_path,collection_name=\"dummydata\",\n",
    "                                    collection_metadata={\"use_type\":\"TRAINING AND EXPERIMENTATION\"} ,\n",
    "                                    metadatas=[{\"course_id\": cid} for cid in df[\"course_id\"]]) ###adding course_id as metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c6bc9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docs dumped into vector DB\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of docs dumped into vector DB\")\n",
    "print(len(vectorstore.get()['ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d22b85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using vector db object to initialize a retriever object - to perform vector search/retrieval\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02b218c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs = retriever.invoke(\"Python Programming for data science\")\n",
    "len(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b21e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Document(id='128d285f-93ce-462b-a653-1e3cce4a17fa', metadata={'course_id': 'C016'}, page_content='Python Programming for Data Science//Learn Python fundamentals for data science: variables, control flow, functions, and object-oriented programming. Advance to data handling with pandas, numerical computing with NumPy, and basic plotting with matplotlib. You’ll build reproducible data workflows, clean and transform datasets, and perform exploratory analysis, laying the groundwork for machine learning and statistical modeling projects.'), 0.16565607488155365)\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "ret_docs = vectorstore.similarity_search_with_score(\"Python programming for data science\",k=5)\n",
    "print(ret_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfae4e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Foundations of Machine Learning//Understand foundational machine learning algorithms including regression, classification, clustering, and dimensionality reduction. This course covers data pre-processing, feature engineering, model selection, hyperparameter tuning, and evaluation metrics. Hands-on labs use scikit-learn and Python to implement end-to-end workflows on real-world datasets, preparing learners for practical machine learning applications with interactive engaging exercises.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs[1].page_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c86def4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform similarity search in Chroma vector store\n",
    "results = vectorstore.similarity_search_with_score(\"python programming for data science\", k=5)\n",
    "\n",
    "# Extract course IDs and similarity scores\n",
    "recommendations = [(doc.metadata[\"course_id\"], score) for doc, score in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6273223e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Document(id='128d285f-93ce-462b-a653-1e3cce4a17fa', metadata={'course_id': 'C016'}, page_content='Python Programming for Data Science//Learn Python fundamentals for data science: variables, control flow, functions, and object-oriented programming. Advance to data handling with pandas, numerical computing with NumPy, and basic plotting with matplotlib. You’ll build reproducible data workflows, clean and transform datasets, and perform exploratory analysis, laying the groundwork for machine learning and statistical modeling projects.'), 0.21110709011554718), (Document(id='02f6a707-a939-406d-916e-4022995801a4', metadata={'course_id': 'C001'}, page_content='Foundations of Machine Learning//Understand foundational machine learning algorithms including regression, classification, clustering, and dimensionality reduction. This course covers data pre-processing, feature engineering, model selection, hyperparameter tuning, and evaluation metrics. Hands-on labs use scikit-learn and Python to implement end-to-end workflows on real-world datasets, preparing learners for practical machine learning applications with interactive engaging exercises.'), 0.39871352910995483), (Document(id='6b214309-6621-44ff-9092-afb5fa3cdbe5', metadata={'course_id': 'C017'}, page_content='R Programming and Statistical Analysis//Get introduced to R for statistical computing and graphics. Topics include data structures, control flow, and functional programming. Use tidyverse libraries—dplyr, ggplot2, tidyr—for data manipulation and visualization. Explore hypothesis testing, regression analysis, and ANOVA. Through labs, apply statistical methods to real-world datasets and communicate results with reproducible R Markdown reports.'), 0.4062874913215637), (Document(id='cde3da1e-3341-4438-8f0a-80070debb9c3', metadata={'course_id': 'C003'}, page_content='Natural Language Processing Fundamentals//Dive into NLP techniques for processing and understanding human language. You will learn tokenization, stemming, lemmatization, part-of-speech tagging, named entity recognition, and sentiment analysis. The course includes transformer architectures, attention mechanisms, and fine-tuning pre-trained language models. Hands-on Python labs use Hugging Face and spaCy for end-to-end natural language pipelines and projects.'), 0.42717573046684265), (Document(id='9568d5be-844e-4f7d-afa1-ca8364893ebe', metadata={'course_id': 'C002'}, page_content='Deep Learning with TensorFlow and Keras//Explore neural network architectures using TensorFlow and Keras frameworks. This course covers feedforward networks, convolutional neural networks, recurrent neural networks, and transfer learning. Learn to build, train, evaluate, and optimize deep learning models for image classification, sequence modeling, and text processing. Includes hands-on labs and real-world project implementations with interactive exercises.'), 0.44606900215148926)]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19301826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('C016', 0.21110709011554718), ('C001', 0.39871352910995483), ('C017', 0.4062874913215637), ('C003', 0.42717573046684265), ('C002', 0.44606900215148926)]\n"
     ]
    }
   ],
   "source": [
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8911f58",
   "metadata": {},
   "source": [
    "Generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb209314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='\\nAnswer this question using the provided context only. list recommendations and comment on relevance. Give the course id as well. ensure to give top 5 recoomended courses\\n.Give the response in markdown format.\\n{question}\\n\\nContext:\\n{context}\\n')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "message = \"\"\"\n",
    "Answer this question using the provided context only. list recommendations and comment on relevance. Give the course id as well. ensure to give top 5 recoomended courses\n",
    ".Give the response in markdown format.\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(message)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77ed78b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags=['Chroma', 'GoogleGenerativeAIEmbeddings'] vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x71b774222450> search_kwargs={'k': 5}\n"
     ]
    }
   ],
   "source": [
    "print(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b143165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(model_name, model_provider=\"google_genai\")\n",
    "\n",
    "rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | llm #using langchain for chaining Runnable pass through is to catch the question in runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "762e4f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context provided, here are the top 5 recommended courses related to Python programming, along with comments on their relevance:\n",
      "\n",
      "**Top 5 Recommended Courses:**\n",
      "\n",
      "1.  **Course ID: C016** - *Python Programming for Data Science*\n",
      "    *   **Relevance:** Highly relevant. This course directly focuses on Python programming, specifically tailored for data science applications. It covers fundamental Python concepts and essential libraries like pandas, NumPy, and matplotlib, crucial for anyone working with data in Python.\n",
      "2.  **Course ID: C004** - *Computer Vision and Image Processing*\n",
      "    *   **Relevance:** Relevant. While not solely focused on basic Python, this course uses Python extensively with libraries like OpenCV, scikit-image, and TensorFlow. It's a good choice if you're interested in applying Python to image-related tasks.\n",
      "3.  **Course ID: C001** - *Foundations of Machine Learning*\n",
      "    *   **Relevance:** Relevant. This course uses Python's scikit-learn library for implementing machine learning algorithms. A good follow-up to a basic Python course if you want to apply your skills to machine learning.\n",
      "4.  **Course ID: C003** - *Natural Language Processing Fundamentals*\n",
      "    *   **Relevance:** Relevant. This course uses Python and libraries like Hugging Face and spaCy for NLP tasks.  It builds upon Python knowledge to process and understand human language.\n",
      "5.  **Course ID: C017** - *R Programming and Statistical Analysis*\n",
      "    *   **Relevance:** Less relevant. This course focuses on R programming, not Python. While statistical analysis is related to data science (which often uses Python), this course does not directly involve Python.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke(\"python programming\")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d224d943",
   "metadata": {},
   "source": [
    "Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c44ca21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on your completion of 'Python Programming for Data Science' and your interest in data visualization, here are the top 5 recommended courses:\n",
      "\n",
      "1.  **Data Visualization with Tableau (C014)**: This course directly builds upon your interest in data visualization. It focuses on using Tableau to create compelling visuals and interactive dashboards. **Relevance:** High, as it aligns perfectly with your stated interest.\n",
      "\n",
      "2.  **R Programming and Statistical Analysis (C017)**: Since you enjoy data visualization, learning R and ggplot2 can provide alternative visualization capabilities. This course also covers statistical analysis, broadening your data science skillset. **Relevance:** High, provides alternative visualization and expands analytical skills.\n",
      "\n",
      "3.  **SQL for Data Analysis (C012)**: SQL is essential for data extraction and manipulation, a critical step before visualization. This course helps you retrieve and prepare data for visualization tools. **Relevance:** Medium, as SQL skills enhance data preparation for visualization.\n",
      "\n",
      "4.  **Foundations of Machine Learning (C001)**:  While not directly related to data visualization, understanding machine learning concepts can provide context for visualizing model results and insights. **Relevance:** Medium, provides context for visualizing model results.\n",
      "\n",
      "5.  **Python Programming for Data Science (C016)**: It is a course that you have already taken. **Relevance:** Low, you have already taken the course.\n"
     ]
    }
   ],
   "source": [
    "response_1 = rag_chain.invoke(\"\"\"I’ve completed the ‘Python Programming for Data Science’ course and enjoy data \n",
    "visualization. What should I take next?\"\"\")\n",
    "\n",
    "print(response_1.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a481c7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on your interest in managing containers and building CI/CD pipelines with your existing Azure knowledge, here are the top 3 recommended courses from the provided context:\n",
      "\n",
      "1.  **Course ID: C009**\n",
      "    *   **Course Title:** Containerization with Docker and Kubernetes\n",
      "    *   **Relevance:** This course directly addresses your interest in container management. It covers Docker and Kubernetes, essential tools for containerizing and orchestrating applications. It's highly relevant for deploying applications on Azure.\n",
      "\n",
      "2.  **Course ID: C008**\n",
      "    *   **Course Title:** DevOps Practices and CI/CD\n",
      "    *   **Relevance:** This course is crucial for building CI/CD pipelines. It covers essential DevOps tools like Git, Jenkins/GitHub Actions, Terraform, and automated testing. It directly aligns with your goal of automating software delivery.\n",
      "\n",
      "3.  **Course ID: C007**\n",
      "    *   **Course Title:** Cloud Computing with Azure\n",
      "    *   **Relevance:** This course is relevant as it covers Azure Kubernetes Service, and other azure services.\n"
     ]
    }
   ],
   "source": [
    "response_2 = rag_chain.invoke(\"\"\"I know Azure basics and want to manage containers and build CI/CD pipelines. \n",
    "Recommend courses.\"\"\")\n",
    "\n",
    "print(response_2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "089c4b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the top 5 recommended courses based on your background and interests, along with relevance comments:\n",
      "\n",
      "1.  **Deep Learning with TensorFlow and Keras (C002)**: Highly relevant. This course directly addresses your interest in neural networks and provides hands-on experience with TensorFlow and Keras, essential frameworks for deep learning.\n",
      "\n",
      "2.  **MLOps: Productionizing Machine Learning (C025)**: Highly relevant. This course is crucial for your goal of specializing in production workflows. It covers the tools and practices for deploying and maintaining ML models at scale.\n",
      "\n",
      "3.  **Computer Vision and Image Processing (C004)**: Relevant. Since you want to specialize in neural networks, this course teaches CNNs which is a type of neural network.\n",
      "\n",
      "4.  **Foundations of Machine Learning (C001)**: Relevant. This course will give you a better understanding of the fundamentals of machine learning.\n",
      "\n",
      "5.  **Reinforcement Learning Basics (C005)**: Somewhat relevant. This course teaches reinforcement learning paradigms, including Markov decision processes, Q-learning, policy gradients, and actor-critic methods.\n"
     ]
    }
   ],
   "source": [
    "response_3 = rag_chain.invoke(\"\"\"My background is in ML fundamentals; I’d like to specialize in neural networks and \n",
    "production workflows..\"\"\")\n",
    "\n",
    "print(response_3.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47c69e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the top 5 recommended courses based on your interest in learning to build and deploy microservices with Kubernetes, along with their relevance and course IDs:\n",
      "\n",
      "1.  **Containerization with Docker and Kubernetes (C009)**\n",
      "    *   **Relevance:** This course directly addresses your request. It covers Docker fundamentals and Kubernetes orchestration, including deploying microservices architectures. It is highly relevant.\n",
      "2.  **APIs and Microservices Architecture (C010)**\n",
      "    *   **Relevance:** This course is also highly relevant. It focuses on designing and implementing APIs and microservices, covering patterns, deployment, versioning, and security. It provides the architectural knowledge needed for building microservices.\n",
      "3.  **Cloud Computing with Azure (C007)**\n",
      "    *   **Relevance:** This course includes Azure Kubernetes Service (AKS). If you plan to deploy your microservices on Azure, this course is very relevant, as it will give you hands-on experience with the cloud platform.\n",
      "4.  **DevOps Practices and CI/CD (C008)**\n",
      "    *   **Relevance:** Deploying microservices effectively requires a strong understanding of DevOps practices and CI/CD pipelines. This course is relevant as it covers these aspects, including container registry integration and automated testing.\n",
      "5.  **Internet of Things (IoT) Development (C022)**\n",
      "    *   **Relevance:** While this course focuses on IoT, the concepts of edge computing, data collection, and cloud service integration could be helpful if your microservices will interact with IoT devices. However, it is less directly relevant than the other courses.\n"
     ]
    }
   ],
   "source": [
    "response_4 = rag_chain.invoke(\"\"\"I want to learn to build and deploy microservices with Kubernetes—what courses fit \n",
    "best?\"\"\")\n",
    "\n",
    "print(response_4.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93206148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on your interest in blockchain and smart contracts with no prior experience, here's a recommended course:\n",
      "\n",
      "**Top Recommendation:**\n",
      "\n",
      "*   **C023 - Blockchain Technology and Smart Contracts:** This course is highly relevant as it directly addresses your interest. It covers blockchain fundamentals like cryptographic hashing, consensus algorithms, and distributed ledgers. It also teaches smart contract development using Solidity on Ethereum, covering token standards, decentralized application patterns, and security best practices. The hands-on labs provide practical experience in deploying contracts and building a decentralized marketplace.\n",
      "\n",
      "The other courses are not relevant to your request.\n"
     ]
    }
   ],
   "source": [
    "response_5 = rag_chain.invoke(\"\"\"I’m interested in blockchain and smart contracts but have no prior experience. Which \n",
    "courses do you suggest?\"\"\")\n",
    "\n",
    "print(response_5.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798e6fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
