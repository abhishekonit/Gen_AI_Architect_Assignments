{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1825b3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Tokens - Non-news parts: 131\n",
      "[DEBUG] Tokens - News summaries combined: 287\n",
      "[DEBUG] Tokens - Total prompt with news: 418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4526/3526556275.py:221: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  mlflow.log_dict(sentiment_profile.dict(), \"sentiment_profile.json\")\n",
      "/tmp/ipykernel_4526/3526556275.py:224: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  return sentiment_profile.dict()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run sentiment-Amazon at: http://20.75.92.162:5000/#/experiments/477038078762324239/runs/9fd793b48cf24cffadfbc915799bcd82\n",
      "ðŸ§ª View experiment at: http://20.75.92.162:5000/#/experiments/477038078762324239\n",
      "Sentiment Profile:\n",
      "{'company_name': 'Amazon', 'stock_code': 'AMZN', 'newsdesc': ['Amazon s 2025 hardware event: the 8 biggest announcements.', 'Amazon just finished up its fall event, where it shared big updates across its entire hardware lineup.', 'In addition to revealing new Echo hardware and Kindle Scribe upgrades, Amazon also took the wraps off refreshed Fire TV devices and a whole bunch more.', 'Here Amazon announces a new Echo Studio.', 'Amazon revealed a new Echo Studio smart speaker at its fall 2025 hardware event on Tuesday.', 'A new speaker wasn t a total surprise, as Amazon s event invite hinted strongly that there might be new Echo devices revealed at the show.', 'The Studio is the most adva Everything Amazon Announced Today at Its Fall Hardware Event 2025 .', \"Amazon's next-gen Alexa chatbot is now available in four new Echo devices and a bevy of Ring cameras.\", 'The company also debuted three new Kindle Scribe tablets, one with a color screen.', 'The Best Sheets on Amazon, Tested by WIRED 2025 .', \"Looking for great sheets you can buy with that Prime membership Here's the best sheets on Amazon, from ultra-cheap bamboo to high-quality cotton percale.\", 'Amazon announces new Echo Show 8 and 11 smart displays.', 'Amazon debuted the new Echo Show 8 and Echo Show 11 during its fall 2025 hardware event on Tuesday, after heavily relying on previous versions of the smart display to demonstrate upgrades coming to its Alexa smart assistant at an event earlier this year.'], 'sentiment': 'Positive', 'people_names': [], 'places_names': [], 'other_companies_referred': ['Ring'], 'related_industries': ['Consumer Electronics', 'E-commerce', 'Smart Home', 'Artificial Intelligence'], 'market_implications': 'The launch of new Echo, Kindle, Fire TV, and Ring products, along with Alexa updates, suggests Amazon is continuing to innovate and expand its presence in the consumer electronics and smart home markets. This could lead to increased revenue and market share.', 'confidence_score': 0.9}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "import mlflow\n",
    "import tiktoken\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# CONFIGURE MLflow & Vertex AI\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://20.75.92.162:5000/\")\n",
    "mlflow.set_experiment(\"market-sentiment-analyzer\")\n",
    "\n",
    "llm = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")\n",
    "\n",
    "# Token utils\n",
    "\n",
    "def count_tokens(text: str, model_name: str = \"gemini-2.0-flash\") -> int:\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model_name)\n",
    "    except KeyError:\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokens = encoding.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "def truncate_text_by_tokens(text: str, max_tokens: int, model_name: str = \"gemini-2.0-flash\") -> str:\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model_name)\n",
    "    except KeyError:\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokens = encoding.encode(text)\n",
    "    if len(tokens) <= max_tokens:\n",
    "        return text\n",
    "    truncated_tokens = tokens[:max_tokens]\n",
    "    truncated_text = encoding.decode(truncated_tokens)\n",
    "    return truncated_text\n",
    "\n",
    "def clean_and_truncate_news(raw_news: str, max_tokens: int = 5000) -> str:\n",
    "    # Remove URLs, emails, excessive whitespace, etc.\n",
    "    text = raw_news\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s.,;:\\'\\\"-]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    truncated = truncate_text_by_tokens(text, max_tokens)\n",
    "    return truncated\n",
    "\n",
    "# Step 1. Get Stock Code\n",
    "\n",
    "def get_stock_code(company_name: str) -> str:\n",
    "    url = f\"https://query1.finance.yahoo.com/v1/finance/search?q={company_name}&lang=en-US&region=US\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    resp = requests.get(url, headers=headers)\n",
    "\n",
    "    if resp.status_code != 200:\n",
    "        raise Exception(f\"Yahoo error: {resp.status_code}: {resp.text}\")\n",
    "\n",
    "    data = resp.json()\n",
    "    try:\n",
    "        return data[\"quotes\"][0][\"symbol\"]\n",
    "    except Exception as e:\n",
    "        raise Exception(\"Unable to extract stock code\") from e\n",
    "\n",
    "\n",
    "# Step 2. Fetch & Summarize News Using NewsAPI.org\n",
    "\n",
    "def fetch_company_news(company_name: str, api_key: str, max_articles=5) -> str:\n",
    "    url = (\n",
    "        f\"https://newsapi.org/v2/everything?\"\n",
    "        f\"q={company_name}&\"\n",
    "        f\"language=en&\"\n",
    "        f\"sortBy=relevance&\"\n",
    "        f\"pageSize={max_articles}&\"\n",
    "        f\"apiKey={api_key}\"\n",
    "    )\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    resp = requests.get(url, headers=headers)\n",
    "\n",
    "    if resp.status_code != 200:\n",
    "        raise Exception(f\"News API error: {resp.status_code} - {resp.text}\")\n",
    "\n",
    "    articles = resp.json().get(\"articles\", [])\n",
    "    news_list = [f\"{article.get('title', '')}. {article.get('description', '')}\" for article in articles]\n",
    "    raw_news = \"\\n\".join(news_list)\n",
    "\n",
    "    return clean_and_truncate_news(raw_news, max_tokens=5000)\n",
    "\n",
    "\n",
    "# Step 3. Define Output Format Model\n",
    "\n",
    "class SentimentProfile(BaseModel):\n",
    "    company_name: str\n",
    "    stock_code: str\n",
    "    newsdesc: List[str]\n",
    "    sentiment: str\n",
    "    people_names: List[str]\n",
    "    places_names: List[str]\n",
    "    other_companies_referred: List[str]\n",
    "    related_industries: List[str]\n",
    "    market_implications: str\n",
    "    confidence_score: float\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=SentimentProfile)\n",
    "\n",
    "# Step 4. LangChain Prompt Template with manual small format instructions\n",
    "\n",
    "\n",
    "simple_format_instructions = \"\"\"\n",
    "Respond ONLY in valid JSON with the following fields:\n",
    "- company_name (string)\n",
    "- stock_code (string)\n",
    "- newsdesc (list of strings)\n",
    "- sentiment (string: Positive, Negative, or Neutral)\n",
    "- people_names (list of strings)\n",
    "- places_names (list of strings)\n",
    "- other_companies_referred (list of strings)\n",
    "- related_industries (list of strings)\n",
    "- market_implications (string)\n",
    "- confidence_score (float between 0 and 1)\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "Analyze the following news for company sentiment and details.\n",
    "\n",
    "Company: {company_name}\n",
    "Stock Code: {stock_code}\n",
    "News Summary: {news_summaries}\n",
    "\n",
    "Please respond in this structured format:\n",
    "{format_instructions}\n",
    "\"\"\",\n",
    "    input_variables=[\"company_name\", \"stock_code\", \"news_summaries\"],\n",
    "    partial_variables={\"format_instructions\": simple_format_instructions}\n",
    ")\n",
    "\n",
    "\n",
    "# Debug token counts before LLM call\n",
    "\n",
    "\n",
    "def debug_token_counts(company_name, stock_code, news_summaries, prompt_template):\n",
    "    prompt_without_news = prompt_template.template.format(\n",
    "        company_name=company_name,\n",
    "        stock_code=stock_code,\n",
    "        news_summaries=\"\",\n",
    "        format_instructions=simple_format_instructions,\n",
    "    )\n",
    "    tokens_non_news = count_tokens(prompt_without_news)\n",
    "    \n",
    "    tokens_news = count_tokens(news_summaries)\n",
    "    \n",
    "    total_tokens = count_tokens(prompt_template.template.format(\n",
    "        company_name=company_name,\n",
    "        stock_code=stock_code,\n",
    "        news_summaries=news_summaries,\n",
    "        format_instructions=simple_format_instructions,\n",
    "    ))\n",
    "\n",
    "    print(f\"[DEBUG] Tokens - Non-news parts: {tokens_non_news}\")\n",
    "    print(f\"[DEBUG] Tokens - News summaries combined: {tokens_news}\")\n",
    "    print(f\"[DEBUG] Tokens - Total prompt with news: {total_tokens}\")\n",
    "\n",
    "# Step 5. Main pipeline function\n",
    "\n",
    "\n",
    "def analyze_company(company_name: str, news_api_key: str) -> dict:\n",
    "    with mlflow.start_run(run_name=f\"sentiment-{company_name}\"):\n",
    "        mlflow.log_param(\"company_name\", company_name)\n",
    "\n",
    "        stock_code = get_stock_code(company_name)\n",
    "        mlflow.log_param(\"stock_code\", stock_code)\n",
    "\n",
    "        news_summary = fetch_company_news(company_name, news_api_key)\n",
    "        mlflow.log_text(news_summary, \"news_summary.txt\")\n",
    "\n",
    "        # Debug token counts\n",
    "        debug_token_counts(company_name, stock_code, news_summary, prompt_template)\n",
    "\n",
    "        # Prepare final prompt\n",
    "        final_prompt = prompt_template.format(\n",
    "            company_name=company_name,\n",
    "            stock_code=stock_code,\n",
    "            news_summaries=news_summary,\n",
    "        )\n",
    "\n",
    "        # Check final prompt tokens again and truncate if necessary\n",
    "        total_tokens = count_tokens(final_prompt)\n",
    "        max_allowed_tokens = 1048575  # Gemini max\n",
    "\n",
    "        if total_tokens > max_allowed_tokens:\n",
    "            # aggressively truncate news summary portion only\n",
    "            allowed_news_tokens = max_allowed_tokens - count_tokens(prompt_template.template.format(\n",
    "                company_name=company_name,\n",
    "                stock_code=stock_code,\n",
    "                news_summaries=\"\",\n",
    "                format_instructions=simple_format_instructions,\n",
    "            ))\n",
    "            truncated_news = truncate_text_by_tokens(news_summary, allowed_news_tokens)\n",
    "            final_prompt = prompt_template.format(\n",
    "                company_name=company_name,\n",
    "                stock_code=stock_code,\n",
    "                news_summaries=truncated_news,\n",
    "            )\n",
    "            #print(f\"[DEBUG] Truncated news summary to fit token limit. New token count: {count_tokens(final_prompt)}\")\n",
    "\n",
    "        # Run LLM\n",
    "        raw_output = llm.invoke(final_prompt)\n",
    "\n",
    "        # print(\"LLM Output:\\n\", raw_output.content)\n",
    "\n",
    "        # Parse output\n",
    "        sentiment_profile = parser.parse(raw_output.content)\n",
    "\n",
    "        # Log output\n",
    "        mlflow.log_dict(sentiment_profile.dict(), \"sentiment_profile.json\")\n",
    "        mlflow.log_metric(\"confidence_score\", sentiment_profile.confidence_score)\n",
    "\n",
    "        return sentiment_profile.dict()\n",
    "\n",
    "\n",
    "\n",
    "# Run example\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    company_name = input(\"Enter the company name: \").strip()\n",
    "    #news_api_key = os.getenv(\"NEWSAPI_KEY\") or input(\"Enter your NewsAPI.org API key: \").strip()\n",
    "    news_api_key='fe3fd9191a6147dd961d7207f4d0716d'\n",
    "    result = analyze_company(company_name, news_api_key)\n",
    "    print(\"Sentiment Profile:\")\n",
    "    print(result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
